{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4035 - Cyber Data Analytics\n",
    "## Lab 1 - Fraud data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit on brightspace (zip file with the name Group_xx.zip)\n",
    "(i) This jupyter file completed with code, plots, figures and report for each question. Additional plots and figures can be created for explanation before the end of each main question. Lab 1 contains 5 main questions, including the bonus. Write the code or explanation below each sub question. For the explanations, include what you would normally include in the report for this lab assignment, for example data pre-processing, hypothesis tested, approach, results, etc.\n",
    "(ii) The libraries needed to run this file. Except for numpy, scikit-learn, pandas, matplotlib\n",
    "\n",
    "Your peers should be able to use the readme section for instructions and be able to run this file. \n",
    "\n",
    "Make sure to keep your answers concise. Maximum number of words is 1000, which you can count with the code below. (You can add around 600 words since we start at around 400)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 863\n"
     ]
    }
   ],
   "source": [
    "# If this cell does not work try running `pip install nbformat`\n",
    "\n",
    "import io\n",
    "from IPython import nbformat\n",
    "\n",
    "nb = nbformat.read(\"Lab1-2021.ipynb\", nbformat.NO_CONVERT)\n",
    "word_count = 0\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "\n",
    "print(\"Word count:\", word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Number :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student 1 \n",
    "### Name : Martijn van Meerten\n",
    "### ID : 4387902\n",
    "\n",
    "## Student 2\n",
    "### Name : Yannick Haveman\n",
    "### ID : 4299078"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readme - Provide instructions - libraries used, location of the data file, etc. Keep it short. Remember your peers will not debug your code and should be able to reproduce the exact output you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Absolute path to the credit card fraud data\n",
    "data_path = \"C:\\\\Users\\Yannick\\Cyber Data Analytics\\data_for_student_case.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Visualization task – 1 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Plot visulations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Describe the visualizations and provide relavant explanations of features and relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imbalance task – 1 A4 – Individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a. Print ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b. Analyse the performance of the classifiers. Explain which method performs best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c. Is using SMOTE a good idea? Why (not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Privacy task – 1 A4 – Individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import re\n",
    "\n",
    "# Read data\n",
    "df1 = pd.read_csv(data_path)\n",
    "\n",
    "# Class label \n",
    "df1 = df1.loc[~(df1['simple_journal'] == 'Refused')]\n",
    "df1.loc[df1['simple_journal'] == 'Chargeback', 'simple_journal'] = 1 #fraud\n",
    "df1.loc[df1['simple_journal'] == 'Settled', 'simple_journal'] = 0\n",
    "\n",
    "# Various feature label encoding\n",
    "card_enc = LabelEncoder()\n",
    "card_enc.fit(df1['card_id'])\n",
    "df1['card_id'] = card_enc.transform(df1.card_id)\n",
    "\n",
    "ip_enc = LabelEncoder()\n",
    "ip_enc.fit(df1['ip_id'])\n",
    "df1['ip_id'] = ip_enc.transform(df1.ip_id)\n",
    "\n",
    "# 4. Date\n",
    "df1['creationdate'] = pd.to_datetime(df1['creationdate'])\n",
    "df1['date'] = df1['creationdate'].dt.date\n",
    "\n",
    "#Encoding, Cleaning the data\n",
    "df1.loc[df1['cardverificationcodesupplied'].isna(),'cardverificationcodesupplied'] = False\n",
    "df1.loc[df1['issuercountrycode'].isna(),'issuercountrycode'] = 'ZZ'\n",
    "df1.loc[df1['shoppercountrycode'].isna(),'shoppercountrycode'] = 'ZZ'\n",
    "\n",
    "unique_issuer_cc = df1['issuercountrycode'].unique()\n",
    "unique_shopper_cc = df1['shoppercountrycode'].unique()\n",
    "both = np.append(unique_issuer_cc, unique_shopper_cc)\n",
    "df_countrycodes = pd.DataFrame(both)\n",
    "unique_codes = df_countrycodes[0].unique()\n",
    "enc = LabelEncoder()\n",
    "enc.fit(unique_codes)\n",
    "df1['issuercountrycode'] = enc.transform(df1.issuercountrycode)\n",
    "df1['shoppercountrycode'] = enc.transform(df1.shoppercountrycode)\n",
    "def conv(row):\n",
    "    currency_dict = {\"BGN\": 1.9558, \"NZD\": 1.6805, \"ILS\": 4.0448, \"RUB\": 72.2099, \"CAD\": 1.5075, \"USD\": 1.1218,\n",
    "                     \"PHP\": 58.125, \"CHF\": 1.1437, \"ZAR\": 16.0224, \"AUD\": 1.5911, \"JPY\": 124.93, \"TRY\": 6.6913,\n",
    "                     \"HKD\": 8.8007, \"MYR\": 4.6314, \"THB\": 35.802, \"HRK\": 7.413, \"NOK\": 9.6678, \"IDR\": 15953.68,\n",
    "                     \"DKK\": 7.4646, \"CZK\": 25.659, \"HUF\": 322.97, \"GBP\": 0.86248, \"MXN\": 21.2829, \"KRW\": 1308.01,\n",
    "                     \"ISK\": 136.2, \"SGD\": 1.5263, \"BRL\": 4.405, \"PLN\": 4.2868, \"INR\": 78.0615, \"RON\": 4.7596,\n",
    "                     \"CNY\": 7.5541, \"SEK\": 10.635}\n",
    "    return row['amount'] / (currency_dict[row['currencycode']]*100)\n",
    "\n",
    "df1['amount_eur'] = df1.apply(lambda x: conv(x), axis=1)\n",
    "\n",
    "\n",
    "enc1 = LabelEncoder()\n",
    "enc1.fit(df1['txvariantcode'])\n",
    "df1['txvariantcode'] = enc1.transform(df1.txvariantcode)\n",
    "\n",
    "enc2 = LabelEncoder()\n",
    "enc2.fit(df1['currencycode'])\n",
    "df1['currencycode'] = enc2.transform(df1.currencycode)\n",
    "\n",
    "enc3 = LabelEncoder()\n",
    "enc3.fit(df1['shopperinteraction'])\n",
    "df1['shopperinteraction'] = enc3.transform(df1.shopperinteraction)\n",
    "\n",
    "df1['accountcode'] = df1['accountcode'].apply(lambda x: re.sub('Account','',x))\n",
    "df1['accountcode_cc'] = 0\n",
    "df1.loc[(df1['accountcode'] == 'UK'),'accountcode_cc'] = 'GB'\n",
    "df1.loc[(df1['accountcode'] == 'Mexico'),'accountcode_cc'] = 'MX'\n",
    "df1.loc[(df1['accountcode'] == 'Sweden'),'accountcode_cc'] = 'SE'\n",
    "df1.loc[(df1['accountcode'] == 'APAC'),'accountcode_cc'] = 'APAC'\n",
    "\n",
    "enc4 = LabelEncoder()\n",
    "enc4.fit(df1['accountcode'])\n",
    "df1['accountcode'] = enc4.transform(df1.accountcode)\n",
    "\n",
    "enccc = LabelEncoder()\n",
    "enccc.fit(df1['accountcode_cc'])\n",
    "df1['accountcode_cc'] = enccc.transform(df1.accountcode_cc)\n",
    "\n",
    "enc5 = LabelEncoder()\n",
    "enc5.fit(df1['cardverificationcodesupplied'])\n",
    "df1['cardverificationcodesupplied'] = enc5.transform(df1.cardverificationcodesupplied)\n",
    "\n",
    "df1.loc[df1['mail_id'].str.contains('na',case=False),'mail_id'] = 'email99999'\n",
    "\n",
    "enc6 = LabelEncoder()\n",
    "enc6.fit(df1['mail_id'])\n",
    "df1['mail_id'] = enc6.transform(df1.mail_id)\n",
    "\n",
    "df1['bookingdate'] = pd.to_datetime(df1['bookingdate'])\n",
    "\n",
    "df1.loc[df1['cvcresponsecode'] > 2,'cvcresponsecode'] = 3\n",
    "\n",
    "#Feature Engineering\n",
    "df1['countries_equal'] = (df1['shoppercountrycode'] == df1['issuercountrycode'])\n",
    "df1.loc[df1['countries_equal'] == False,'countries_equal'] = 0\n",
    "df1.loc[df1['countries_equal'] == True,'countries_equal'] = 1\n",
    "\n",
    "df1['day_of_week'] = df1['creationdate'].dt.dayofweek\n",
    "\n",
    "df1['hour'] = df1['creationdate'].dt.hour\n",
    "\n",
    "original_data_df = df1.copy()\n",
    "\n",
    "keep_cols = [\n",
    "    \"issuercountrycode\",\n",
    "    \"txvariantcode\",\n",
    "    \"bin\",\n",
    "    \"amount\",\n",
    "    \"currencycode\",\n",
    "    \"shoppercountrycode\",\n",
    "    \"shopperinteraction\",\n",
    "    \"cardverificationcodesupplied\",\n",
    "    \"cvcresponsecode\",\n",
    "    \"accountcode\",\n",
    "    \"mail_id\",\n",
    "    \"ip_id\",\n",
    "    \"card_id\",\n",
    "    \"accountcode_cc\",\n",
    "    \"simple_journal\",\n",
    "    \"day_of_week\",\n",
    "    \"hour\"\n",
    "]\n",
    "\n",
    "df1 = df1[keep_cols]\n",
    "\n",
    "y = df1[\"simple_journal\"].to_numpy().astype(int)\n",
    "df1.drop(columns=\"simple_journal\", inplace=True)\n",
    "df2 = df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Print ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [RandomForestClassifier(random_state=1), GaussianNB(), DecisionTreeClassifier(random_state=1)]\n",
    "classifier_names = ['Random forest', 'GaussianNB', 'Decision Tree']\n",
    "ranking_names = ['rank_by_seller_first', 'rank_by_seller_last', 'rank_by_day_of_week']\n",
    "\n",
    "colors = ['blue', 'red', 'green']\n",
    "fig, axs = plt.subplots(1, 3, figsize=(17,5))\n",
    "k_fold = StratifiedKFold(n_splits=10)\n",
    "for j in range(len(ranking_names)):\n",
    "    if j == 0:\n",
    "        df1 = df2\n",
    "        df1['rank_transaction_by_seller_first'] = df1.groupby(['accountcode', 'shoppercountrycode'])['cvcresponsecode'].rank(method='first')\n",
    "        df1.sort_values(by=['accountcode', 'rank_transaction_by_seller_first'])\n",
    "\n",
    "        df1[df1['rank_transaction_by_seller_first'] == 1]\n",
    "\n",
    "        X = df1.to_numpy().astype(float)\n",
    "    elif j == 1:\n",
    "        df1 = df2\n",
    "        df1['rank_transaction_by_seller_last'] = df1.groupby(['accountcode', 'shoppercountrycode'])['cvcresponsecode'].rank(method='last')\n",
    "        df1.sort_values(by=['accountcode', 'rank_transaction_by_seller_last'])\n",
    "\n",
    "        df1[df1['rank_transaction_by_seller_last'] == 1]\n",
    "\n",
    "        X = df1.to_numpy().astype(float)        \n",
    "    else:\n",
    "        df1 = df2\n",
    "        df1['rank_transaction_by_day_of_week'] = df1.groupby(['accountcode', 'shoppercountrycode'])['day_of_week'].rank(method='first')\n",
    "        df1.sort_values(by=['accountcode', 'rank_transaction_by_day_of_week'])\n",
    "\n",
    "        df1[df1['rank_transaction_by_day_of_week'] == 1]\n",
    "\n",
    "        X = df1.to_numpy().astype(float)\n",
    "    for i in range(len(classifier_names)):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        \n",
    "        for train_index, test_index in k_fold.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            classifiers[i].fit(X_train, y_train)\n",
    "\n",
    "            y_pred_proba = classifiers[i].predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "            aucs.append(roc_auc)\n",
    "        \n",
    "        print(classifiers[i], \"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        mean_auc = auc(mean_fpr, mean_tpr)\n",
    "        std_auc = np.std(aucs)\n",
    "\n",
    "        axs[j].plot(mean_fpr, mean_tpr, label=r'%s (AUC = %0.2f $\\pm$ %0.2f)' % (classifier_names[i], mean_auc, std_auc), color=colors[i])\n",
    "\n",
    "        std_tpr = np.std(tprs, axis=0)\n",
    "        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "        axs[j].fill_between(mean_fpr, tprs_lower, tprs_upper, color=colors[i], alpha=.2)\n",
    "    \n",
    "    axs[j].legend(loc=\"lower right\")\n",
    "    axs[j].set(xlim=[0, 1], ylim=[0, 1], title=ranking_names[j], xlabel=\"False positive rate\", ylabel=\"True positive rate\")\n",
    "    axs[j].plot([0, 1], [0, 1], c=\"gray\", linestyle=\"--\")\n",
    "\n",
    "fig.suptitle('Results after Maxing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Analyse the performance of the classifiers. Explain which method performs best.\n",
    "\n",
    "Looking at all of the classifiers used to test the data provided it seems that the Random Forest classifier outperforms the other classifiers used. The classifier does provide really good results, however, but the time it takes to run is much higher than the other methods. The Gaussian classifer scores a bit lower than the Random Forest, but the time it takes to calculate is less than 1/100. Both the running time and performance of the Decission Tree classifier seem to be alright, but it's outperformed by the Gaussian Classifier. Hence, it can be determined that the Random Forest classifier is the best to use when one has the time to perform the calculations, but if one wants to arrive at results quickly it's best to use the Gaussian Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Can you explain the performance difference for the different classifiers? Is it advisable to protect people’s privacy using rank-swapping? Why (not)?\n",
    "\n",
    "Looking at all of the classifiers used to test the data provided it seems that the Random Forest classifier outperforms the other classifiers used. The classifier does provide really good results, however, but the time it takes to run is much higher than the other methods. The Gaussian classifier scores a bit lower than the Random Forest, but the time it takes to calculate is less than 1/100. Both the running time and performance of the Decision Tree classifier seem to be alright, but it's outperformed by the Gaussian Classifier. Hence, it can be determined that the Random Forest classifier is the best to use when one has the time to perform the calculations, but if one wants to arrive at results quickly it's best to use the Gaussian Classifier\n",
    "\n",
    "The Gaussian classifier is very easy to run calculation wise, which is a very important deciding factor for the run time. Nonetheless, the speed of the calculations aren't that detrimental for the results as it's still very accurate. The decision Tree is known for its simplicity and ability to still provide correct results regardless. It's good for creating accurate models, but as seen it is outperformed by other classifiers in this situation. However, I expect it to perform better in other scenarios such as data mining. The Random Forest is built upon the Decision Tree classifier of which the Forest uses an average of Trees in the forest. All of these Trees contain a subset of features.\n",
    "\n",
    "I'd say that it is advisable to use Rank-Swapping as it performs well and quickly. Given that the privacy is also harnessed adds to the strength of the method. The ranking however, is important for the final result and that should be taken into when deciding on how to use the method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification task – 2 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Print relevant plots and metrics with clear headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Explain the applied data pre-processing steps, learning algorithms, and post-processing steps or ensemble methods. Compare the performance of the two algorithms, focusing on performance criteria that are relevant in practice, use 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus task – 1 A4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a. Provide code and report below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
