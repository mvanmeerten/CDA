{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cb1eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\martijn.vanmeerten\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\IPython\\nbformat.py:12: ShimWarning: The `IPython.nbformat` package has been deprecated since IPython 4.0. You should import from nbformat instead.\n",
      "  warn(\"The `IPython.nbformat` package has been deprecated since IPython 4.0. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count: 287\n"
     ]
    }
   ],
   "source": [
    "# If this cell does not work try running `pip install nbformat`\n",
    "\n",
    "import io\n",
    "from IPython import nbformat\n",
    "\n",
    "nb = nbformat.read(\"lab3_Frequent_Sketching.ipynb\", nbformat.NO_CONVERT)\n",
    "word_count = 0\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "\n",
    "print(\"Word count:\", word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6296f65",
   "metadata": {},
   "source": [
    "## Group Number : 33\n",
    "### Name : Martijn van Meerten\n",
    "### ID : 4387902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb69847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d9a38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('./dataset_10/capture20110818.binetflow', sep=\",\")\n",
    "df = df[df['Label'].map(lambda x: 'Background' not in str(x))]\n",
    "df.loc[df['State'].isna(),'State'] = 'NA'\n",
    "state_enc = LabelEncoder()\n",
    "state_enc.fit(df['State'])\n",
    "df['State'] = state_enc.transform(df.State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2dc8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_tot_bytes(dataframe):    \n",
    "    totBytesBins = [-1, 800, 1300, 1900, 10000, dataframe['TotBytes'].max()]\n",
    "    totBytesLabels=[1,2,3,4,5]\n",
    "    dataframe['TotBytes_disc'] = pd.cut(dataframe['TotBytes'], bins=totBytesBins, labels=totBytesLabels)\n",
    "    \n",
    "def discretize_state(dataframe):\n",
    "    totStateBins = [-1, 20, 40, 60, 80, 100, dataframe['State'].max() + 1]\n",
    "    totStateLabels=[1,2,3,4,5,6]\n",
    "    dataframe['State_disc'] = pd.cut(dataframe['State'], bins=totStateBins, labels=totStateLabels)\n",
    "    \n",
    "def combine_discrete_values(row, key1, key2):\n",
    "    return int(str(int(row[key1])) + str(int(row[key2])))\n",
    "\n",
    "def df_combine_discretization(dataframe):\n",
    "    dataframe['disc'] = dataframe.apply (lambda row: combine_discrete_values(row, 'State_disc', 'TotBytes_disc'), axis=1)\n",
    "    \n",
    "discretize_tot_bytes(df)\n",
    "discretize_state(df)\n",
    "df_combine_discretization(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc53d1",
   "metadata": {},
   "source": [
    "## 2. Frequent task – 1/2 A4 (Individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cfcaa4",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c569d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate occurrences of n-grams\n",
    "def space_saving(k, three_grams):\n",
    "    # Store counters in a dictionary\n",
    "    value_counter = dict()\n",
    "    for three_gram in three_grams:\n",
    "        # If the 3-gram is already in the counter, increment\n",
    "        if three_gram in value_counter:\n",
    "            value_counter[three_gram] += 1\n",
    "        # Else if there is room add the 3-gram with count 1\n",
    "        elif len(value_counter) < k-1:\n",
    "            value_counter[three_gram] = 1\n",
    "        # Else find the 3-gram with min count, delete that 3-gram\n",
    "        # and assign and increment its count to the new 3-gram\n",
    "        else:\n",
    "            key = min(value_counter, key=value_counter.get)\n",
    "            min_count = value_counter[key]\n",
    "            del value_counter[key]\n",
    "            value_counter[three_gram] = min_count + 1\n",
    "                    \n",
    "    return value_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff727f5",
   "metadata": {},
   "source": [
    "### 2a. Use the SPACE SAVING algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99fb7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532        35\n",
      "822        12\n",
      "842        12\n",
      "1021       11\n",
      "1022       11\n",
      "           ..\n",
      "1309670    11\n",
      "1309736    11\n",
      "1309782    11\n",
      "1309783    11\n",
      "1309784    51\n",
      "Name: disc, Length: 122199, dtype: int64\n",
      "[(35, 12, 12), (12, 12, 11), (12, 11, 11), (11, 11, 21), (11, 21, 35), (21, 35, 34), (35, 34, 35), (34, 35, 35), (35, 35, 35), (35, 35, 35)]\n"
     ]
    }
   ],
   "source": [
    "disc = df['disc']\n",
    "# Get the 3-grams of the discretized value\n",
    "three_grams = list(map(tuple, [disc[i:i+3] for i in range(len(df)-2)]))\n",
    "print(disc)\n",
    "print(three_grams[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ccc1398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122199\n",
      "k = 100\n",
      "Frequencies: [((62, 62, 62), 51996), ((11, 11, 11), 3531), ((42, 62, 62), 3233), ((62, 62, 42), 3219), ((62, 42, 62), 3174), ((62, 32, 62), 2916), ((62, 62, 32), 2911), ((32, 62, 62), 2894), ((62, 64, 62), 2673), ((62, 62, 64), 2664)]\n",
      "Errors: [10, 0, 11, 11, 11, 12, 12, 10, 11, 11]\n",
      "\n",
      "k = 300\n",
      "Frequencies: [((62, 62, 62), 51987), ((11, 11, 11), 3531), ((42, 62, 62), 3223), ((62, 62, 42), 3209), ((62, 42, 62), 3164), ((62, 32, 62), 2905), ((62, 62, 32), 2900), ((32, 62, 62), 2885), ((62, 64, 62), 2663), ((62, 62, 64), 2654)]\n",
      "Errors: [1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "k = 500\n",
      "Frequencies: [((62, 62, 62), 51986), ((11, 11, 11), 3531), ((42, 62, 62), 3222), ((62, 62, 42), 3208), ((62, 42, 62), 3163), ((62, 32, 62), 2904), ((62, 62, 32), 2899), ((32, 62, 62), 2884), ((62, 64, 62), 2662), ((62, 62, 64), 2653)]\n",
      "Errors: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "True frequencies = [51986, 3531, 3222, 3208, 3163, 2904, 2899, 2884, 2662, 2653]\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "number_of_counters = [100, 300, 500]\n",
    "frequencies = []\n",
    "# Calculate frequencies for different numbers of counters\n",
    "for i in number_of_counters:\n",
    "    value_counter = space_saving(i, three_grams)\n",
    "    frequencies.append(sorted(value_counter.items(), key=lambda item: item[1], reverse=True)[:10])\n",
    "    \n",
    "# Calculate the true frequency of the 3-grams\n",
    "true_frequency = []\n",
    "for ngram, _ in frequencies[0]:\n",
    "    true_frequency.append(three_grams.count(ngram))\n",
    "    \n",
    "# Calculate the error between the approximated and true frequencies\n",
    "def calculate_errors(frequencies, true_frequency):\n",
    "    errors = []\n",
    "    for approximation in frequencies:\n",
    "        error = []\n",
    "        for index, (ngram, value) in enumerate(approximation):\n",
    "            error.append(value - true_frequency[index])\n",
    "\n",
    "        errors.append(error)\n",
    "    \n",
    "    return errors\n",
    "\n",
    "errors = calculate_errors(frequencies, true_frequency)\n",
    "    \n",
    "# Print results\n",
    "for index, error in enumerate(errors):\n",
    "    print(f'k = {number_of_counters[index]}')\n",
    "    print(f'Frequencies: {frequencies[index]}')\n",
    "    print(f'Errors: {error}\\n')\n",
    "\n",
    "print(f'True frequencies = {true_frequency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcbee2",
   "metadata": {},
   "source": [
    "### 2b. Analysis and answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f972517",
   "metadata": {},
   "source": [
    "All counts found by the space saving algorithm are overestimates. The overestimate is at most $n/k$, so a higher $k$ results in a more accurate approximation. This is however a trade-off in terms of space complexity, as the memory required for the algorithm increases with $k$, the number of counters. \\\n",
    "\\\n",
    "This also follows from the results above. For $k = 100$, the algorithm overestimates by roughly 10 counts, while at $k = 500$, there are no approximation errors. The 10 most frequent 3-grams can also be found in the results above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16fd28",
   "metadata": {},
   "source": [
    "## 3. Sketching task – 1/2 A4 (Individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420bc97",
   "metadata": {},
   "source": [
    "### 3a. COUNT-MIN sketch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6512a60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = 50, d = 10\n",
      "Frequencies: [((62, 62, 62), 52184), ((11, 11, 11), 3769), ((62, 42, 62), 3522), ((62, 62, 42), 3428), ((42, 62, 62), 3335), ((62, 62, 32), 3080), ((32, 62, 62), 3052), ((62, 32, 62), 3033), ((62, 62, 15), 2874), ((62, 15, 62), 2870)]\n",
      "Errors: [198, 238, 300, 220, 172, 176, 153, 149, 212, 217]\n",
      "\n",
      "w = 50, d = 20\n",
      "Frequencies: [((62, 62, 62), 52089), ((11, 11, 11), 3565), ((62, 62, 42), 3384), ((62, 42, 62), 3355), ((42, 62, 62), 3323), ((62, 62, 32), 3040), ((62, 32, 62), 3012), ((32, 62, 62), 3005), ((62, 62, 64), 2810), ((15, 62, 62), 2755)]\n",
      "Errors: [103, 34, 162, 147, 160, 136, 113, 121, 148, 102]\n",
      "\n",
      "w = 50, d = 40\n",
      "Frequencies: [((62, 62, 62), 52098), ((11, 11, 11), 3782), ((42, 62, 62), 3330), ((62, 62, 42), 3292), ((62, 42, 62), 3276), ((62, 62, 32), 3063), ((32, 62, 62), 2995), ((62, 32, 62), 2990), ((62, 62, 64), 2805), ((62, 15, 62), 2763)]\n",
      "Errors: [112, 251, 108, 84, 113, 159, 96, 106, 143, 110]\n",
      "\n",
      "w = 50, d = 80\n",
      "Frequencies: [((62, 62, 62), 52079), ((11, 11, 11), 3550), ((62, 42, 62), 3305), ((62, 62, 42), 3302), ((42, 62, 62), 3291), ((32, 62, 62), 3042), ((62, 62, 32), 2995), ((62, 32, 62), 2956), ((62, 64, 62), 2766), ((62, 62, 64), 2757)]\n",
      "Errors: [93, 19, 83, 94, 128, 138, 96, 72, 104, 104]\n",
      "\n",
      "w = 100, d = 10\n",
      "Frequencies: [((62, 62, 62), 52031), ((11, 11, 11), 3595), ((62, 62, 42), 3435), ((42, 62, 62), 3311), ((62, 42, 62), 3203), ((32, 62, 62), 2998), ((62, 62, 32), 2963), ((62, 32, 62), 2918), ((64, 62, 62), 2717), ((62, 64, 62), 2714)]\n",
      "Errors: [45, 64, 213, 103, 40, 94, 64, 34, 55, 61]\n",
      "\n",
      "w = 100, d = 20\n",
      "Frequencies: [((62, 62, 62), 52014), ((11, 11, 11), 3600), ((42, 62, 62), 3259), ((62, 62, 42), 3233), ((62, 42, 62), 3188), ((62, 32, 62), 2965), ((32, 62, 62), 2932), ((62, 62, 32), 2915), ((62, 62, 64), 2677), ((62, 64, 62), 2674)]\n",
      "Errors: [28, 69, 37, 25, 25, 61, 33, 31, 15, 21]\n",
      "\n",
      "w = 100, d = 40\n",
      "Frequencies: [((62, 62, 62), 52013), ((11, 11, 11), 3551), ((42, 62, 62), 3254), ((62, 62, 42), 3227), ((62, 42, 62), 3193), ((62, 32, 62), 2930), ((62, 62, 32), 2922), ((32, 62, 62), 2909), ((62, 64, 62), 2692), ((62, 62, 64), 2675)]\n",
      "Errors: [27, 20, 32, 19, 30, 26, 23, 25, 30, 22]\n",
      "\n",
      "w = 100, d = 80\n",
      "Frequencies: [((62, 62, 62), 52005), ((11, 11, 11), 3573), ((42, 62, 62), 3239), ((62, 62, 42), 3230), ((62, 42, 62), 3196), ((62, 32, 62), 2917), ((62, 62, 32), 2914), ((32, 62, 62), 2912), ((62, 64, 62), 2687), ((62, 62, 64), 2671)]\n",
      "Errors: [19, 42, 17, 22, 33, 13, 15, 28, 25, 18]\n",
      "\n",
      "w = 150, d = 10\n",
      "Frequencies: [((62, 62, 62), 52019), ((11, 11, 11), 3580), ((42, 62, 62), 3246), ((62, 62, 42), 3225), ((62, 42, 62), 3190), ((62, 62, 32), 2952), ((62, 32, 62), 2918), ((32, 62, 62), 2903), ((62, 62, 64), 2680), ((62, 64, 62), 2667)]\n",
      "Errors: [33, 49, 24, 17, 27, 48, 19, 19, 18, 14]\n",
      "\n",
      "w = 150, d = 20\n",
      "Frequencies: [((62, 62, 62), 52000), ((11, 11, 11), 3544), ((62, 62, 42), 3232), ((42, 62, 62), 3229), ((62, 42, 62), 3187), ((62, 32, 62), 2918), ((62, 62, 32), 2901), ((32, 62, 62), 2893), ((62, 64, 62), 2672), ((62, 62, 64), 2654)]\n",
      "Errors: [14, 13, 10, 21, 24, 14, 2, 9, 10, 1]\n",
      "\n",
      "w = 150, d = 40\n",
      "Frequencies: [((62, 62, 62), 51991), ((11, 11, 11), 3542), ((42, 62, 62), 3228), ((62, 62, 42), 3218), ((62, 42, 62), 3167), ((62, 32, 62), 2916), ((62, 62, 32), 2914), ((32, 62, 62), 2896), ((62, 64, 62), 2668), ((62, 62, 64), 2661)]\n",
      "Errors: [5, 11, 6, 10, 4, 12, 15, 12, 6, 8]\n",
      "\n",
      "w = 150, d = 80\n",
      "Frequencies: [((62, 62, 62), 51994), ((11, 11, 11), 3538), ((42, 62, 62), 3236), ((62, 62, 42), 3222), ((62, 42, 62), 3166), ((62, 32, 62), 2908), ((62, 62, 32), 2899), ((32, 62, 62), 2894), ((62, 64, 62), 2668), ((62, 62, 64), 2663)]\n",
      "Errors: [8, 7, 14, 14, 3, 4, 0, 10, 6, 10]\n",
      "\n",
      "w = 200, d = 10\n",
      "Frequencies: [((62, 62, 62), 51999), ((11, 11, 11), 3537), ((42, 62, 62), 3233), ((62, 62, 42), 3215), ((62, 42, 62), 3172), ((62, 62, 32), 2913), ((62, 32, 62), 2905), ((32, 62, 62), 2893), ((62, 64, 62), 2677), ((62, 62, 64), 2656)]\n",
      "Errors: [13, 6, 11, 7, 9, 9, 6, 9, 15, 3]\n",
      "\n",
      "w = 200, d = 20\n",
      "Frequencies: [((62, 62, 62), 51989), ((11, 11, 11), 3533), ((42, 62, 62), 3229), ((62, 62, 42), 3217), ((62, 42, 62), 3177), ((62, 32, 62), 2910), ((62, 62, 32), 2902), ((32, 62, 62), 2896), ((62, 64, 62), 2667), ((62, 62, 64), 2654)]\n",
      "Errors: [3, 2, 7, 9, 14, 6, 3, 12, 5, 1]\n",
      "\n",
      "w = 200, d = 40\n",
      "Frequencies: [((62, 62, 62), 51991), ((11, 11, 11), 3533), ((42, 62, 62), 3226), ((62, 62, 42), 3217), ((62, 42, 62), 3167), ((62, 32, 62), 2913), ((62, 62, 32), 2900), ((32, 62, 62), 2888), ((62, 64, 62), 2669), ((62, 62, 64), 2658)]\n",
      "Errors: [5, 2, 4, 9, 4, 9, 1, 4, 7, 5]\n",
      "\n",
      "w = 200, d = 80\n",
      "Frequencies: [((62, 62, 62), 51989), ((11, 11, 11), 3533), ((42, 62, 62), 3227), ((62, 62, 42), 3212), ((62, 42, 62), 3168), ((62, 32, 62), 2908), ((62, 62, 32), 2902), ((32, 62, 62), 2885), ((62, 64, 62), 2664), ((62, 62, 64), 2656)]\n",
      "Errors: [3, 2, 5, 4, 5, 4, 3, 1, 2, 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "# Generate random values for the hash function. Different values everytime count_min_sketch is run\n",
    "def generate_random_seeds(d):\n",
    "    global a\n",
    "    global b\n",
    "    a = random.sample(range(1, (2**61 - 2)), d)\n",
    "    b = random.sample(range(0, (2**61 - 2)), d)\n",
    "\n",
    "# Pairwise independen hash function\n",
    "def pairwise_independent_hashes(ngram, w, d):\n",
    "    # Combine the 3-gram into a single 6-digit integer\n",
    "    combined = ''\n",
    "    for x in ngram:\n",
    "        combined += str(x)\n",
    "    \n",
    "    combinedInt = int(combined)\n",
    "    hashes = []\n",
    "    # Hash this according to h(x) = a*x + b % p % w\n",
    "    # Gives d different hash results between 0 and w\n",
    "    for i in range(d):\n",
    "        hashh = ((a[i] * combinedInt + b[i]) % (2**61 - 1)) % w\n",
    "        hashes.append(hashh)\n",
    "    \n",
    "    return hashes\n",
    "\n",
    "def count_min_sketch(w, d, ngrams):\n",
    "    generate_random_seeds(d)\n",
    "    # Construct d x w table\n",
    "    table = [[0 for _ in range(w)] for _ in range(d)]\n",
    "    for ngram in ngrams:\n",
    "        hashed_values = pairwise_independent_hashes(ngram, w, d)\n",
    "        for index, value in enumerate(hashed_values):\n",
    "            table[index][value] += 1\n",
    "            \n",
    "    return table\n",
    "\n",
    "# Lookup frequency of an ngram\n",
    "def point_lookup(ngram, table):\n",
    "    d = len(table)\n",
    "    w = len(table[0])\n",
    "    min_count = float('inf')\n",
    "    # Find the row with the minimum count for ngram and return it\n",
    "    hashed_values = pairwise_independent_hashes(ngram, w, d)\n",
    "    for index, value in enumerate(hashed_values):\n",
    "        count = table[index][value]\n",
    "        if count < min_count:\n",
    "            min_count = count\n",
    "    \n",
    "    return min_count\n",
    "\n",
    "\n",
    "ws = [50, 100, 150, 200]\n",
    "ds = [10, 20, 40, 80]\n",
    "\n",
    "frequencies = []\n",
    "for w in ws:\n",
    "    for d in ds:\n",
    "        table = count_min_sketch(w, d, three_grams)\n",
    "        frequency = []\n",
    "        for ngram in set(three_grams):\n",
    "            frequency.append((ngram, point_lookup(ngram, table)))\n",
    "            \n",
    "        frequencies.append(sorted(frequency, key=lambda item: item[1], reverse=True)[:10])\n",
    "            \n",
    "        \n",
    "errors = calculate_errors(frequencies, true_frequency)\n",
    "for index, error in enumerate(errors):\n",
    "    print(f'w = {ws[math.floor(index/len(ds))]}, d = {ds[index % len(ws)]}')\n",
    "    print(f'Frequencies: {frequencies[index]}')\n",
    "    print(f'Errors: {error}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6742ac37",
   "metadata": {},
   "source": [
    "### 3b. Analysis and answers to the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51055961",
   "metadata": {},
   "source": [
    "The hash function used is $h(x) = aX + b \\mod p \\mod d$. The 3-gram is combined into a 6 digit integer and the hash function maps this value to between $0$ and $d$. Two hash functions with different $a$ and $b$ are pair-wise independent and therefore suited for count-min sketch.\n",
    "\n",
    "Count-min sketch overestimates its approximations. The overestimate is:  ${\\hat {a}}_{i}\\leq a_{i}+\\varepsilon N$ with probability $1-\\delta$, where $\\varepsilon = e / w$, $\\delta = 1 / e^d$ and $N$ is the stream size. So by increasing $w$ and $d$ we reduce the overestimatation factor and probability, but also increase the size and time complexity. This also shows from the results, where with $w=50$ and $d=10$, the number of errors are quite substantial, while the errors with $w=200$ and $d=80$, are around 4. The 10 most frequent 3-grams can also be found in the results above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
